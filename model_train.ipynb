{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","Root = \"./Ravdess_data\"\n","os.chdir(Root)\n","import librosa\n","import soundfile\n","import os, glob, pickle\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{},"source":["\n","#Extract features (mfcc, chroma, mel) from a soundfile"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def extract_features(file_name, mfcc, chroma,mel):\n","    with soundfile.SoundFile(file_name) as sound_file:\n","        X = sound_file.read(dtype=\"float32\")\n","        sample_rate=sound_file.samplerate\n","        if chroma:\n","            stft=np.abs(librosa.stft(X))\n","        result=np.array([])\n","        if mfcc:\n","            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n","            result= np.hstack((result, mfccs))\n","        if chroma:\n","            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n","            result=np.hstack( (result, chroma))\n","        if mel:\n","            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n","            result=np.hstack((result, mel))\n","    return result\n"]},{"cell_type":"markdown","metadata":{},"source":["# Emotions in the RAVDESS dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","emotions={\n","    '01':'neutral',\n","    '02':'calm',\n","    '03':'happy',\n","    '04':'sad',\n","    '05':'angry',\n","    '06':'fearful',\n","    '07':'disgust',\n","    '08':'surprised',\n","}"]},{"cell_type":"markdown","metadata":{},"source":["emotions to observe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["observed_emotions=['neutral', 'happy', 'fearful', 'sad']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the data and extract features for each sound file"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load_data(test_size=0.2):\n","    x,y=[],[]\n","    for file in glob.glob(\"D:/Code/Ravdess_data/Actor_*/*.wav\"):\n","        file_name=os.path.basename(file)\n","        emotion=emotions[file_name.split(\"-\")[2]]\n","        if emotion not in observed_emotions:\n","            continue\n","        feature=extract_features(file, mfcc=True, chroma=True, mel=True)\n","        x.append(feature)\n","        y.append(emotion)\n","    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Split the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train,x_test,y_train,y_test=load_data(test_size=0.25)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Get the shape of the training and testing datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print((x_train.shape[0], x_test.shape[0]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Get the number of features extracted"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f'features extracted: {x_train.shape[1]}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Initialize the Multi Layer Perception Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=600)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.fit(x_train, y_train)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Predict for the set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred=model.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Calculate the accuracy of our model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Print the accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Accuracy: {:.2f}%\".format(accuracy*100))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f1_score(y_test, y_pred,average=None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","df=pd.DataFrame({'Actual': y_test, 'Predicted':y_pred})\n","df.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle\n","#Writing different model files to file\n","filename = 'modelForPrediction1'\n","pickle.dump(model,open(filename,'wb'))\n","    \n","\n","loaded_model = pickle.load(open(filename, 'rb'))  #loading the model file from the storage"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature=extract_features(\"./Ravdess_data/Actor_15/03-01-01-01-01-01-15.wav\", mfcc=True, chroma=True, mel=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature=feature.reshape(1,-1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prediction=loaded_model.predict(feature)\n","print(prediction[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"4c98853d42e796f7a56c600d57528e01d7241b0f929f2e2e48ff7509c216d37c"}}},"nbformat":4,"nbformat_minor":2}
